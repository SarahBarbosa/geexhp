{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_paths(root_folder):\n",
    "    files = os.listdir(root_folder)\n",
    "\n",
    "    data = {\n",
    "        'modern' : {\n",
    "            'file_paths' : [],\n",
    "            'file_numbers_of_samples' : []\n",
    "        },\n",
    "        'proterozoic' : {\n",
    "            'file_paths' : [],\n",
    "            'file_numbers_of_samples' : []\n",
    "        },\n",
    "        'archean' : {\n",
    "            'file_paths' : [],\n",
    "            'file_numbers_of_samples' : []\n",
    "        },\n",
    "    }\n",
    "\n",
    "    for file in files:\n",
    "        era = file.split('/')[-1].split('_')[0]\n",
    "\n",
    "        data[era]['file_paths'].append(os.path.join(root_folder, file))\n",
    "        data[era]['file_numbers_of_samples'].append(int(file.split('_')[-1].split('.')[0]))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_era(root_folder, train_split = 0.8, val_split = 0.1):\n",
    "    tf_data = load_dataset_paths(root_folder)\n",
    "\n",
    "    split_indexes = {\n",
    "        'train' : False,\n",
    "        'val' : False,\n",
    "    }\n",
    "\n",
    "    # We do it for each era so that the dataset can be stratified.\n",
    "    for era in list(tf_data.keys()):\n",
    "        total_number_of_samples = sum(tf_data[era]['file_numbers_of_samples'])\n",
    "\n",
    "        count = 0\n",
    "        for index, num_samples in enumerate(tf_data[era]['file_numbers_of_samples']):\n",
    "            if (count >= total_number_of_samples * (train_split)) and (split_indexes['train'] == False):\n",
    "                split_indexes['train'] = index\n",
    "\n",
    "            if count >= total_number_of_samples * (train_split + val_split):\n",
    "                split_indexes['val'] = index\n",
    "                break\n",
    "            \n",
    "            count += num_samples\n",
    "        \n",
    "\n",
    "        tf_data[era]['split_indexes'] = split_indexes\n",
    "    \n",
    "    return tf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split_concatenate(root_folder):\n",
    "    tf_data = split_era(root_folder)\n",
    "\n",
    "    # All splits must be the same for all eras.\n",
    "    train_split = tf_data['modern']['split_indexes']['train']\n",
    "    val_split = tf_data['modern']['split_indexes']['val']\n",
    "\n",
    "    data_types_paths = {\n",
    "        'train' : tf_data['modern']['file_paths'][:train_split] + tf_data['proterozoic']['file_paths'][:train_split] + tf_data['archean']['file_paths'][:train_split],\n",
    "\n",
    "        'val' : tf_data['modern']['file_paths'][train_split:val_split] + tf_data['proterozoic']['file_paths'][train_split:val_split] + tf_data['archean']['file_paths'][train_split:val_split],\n",
    "\n",
    "        'test' : tf_data['modern']['file_paths'][val_split:] + tf_data['proterozoic']['file_paths'][val_split:] + tf_data['archean']['file_paths'][val_split:]\n",
    "    }\n",
    "\n",
    "    for data_type in list(data_types_paths.keys()):\n",
    "        # Output TFRecord file\n",
    "        output_tfrecord_file = f'../data/geexhp_{data_type}_samples.tfrecord'\n",
    "\n",
    "        # Write concatenated records to a new TFRecord file\n",
    "        with tf.io.TFRecordWriter(output_tfrecord_file) as writer:\n",
    "            for tfrecord_file in data_types_paths[data_type]:\n",
    "                # Read each TFRecord file\n",
    "                for record in tf.data.TFRecordDataset(tfrecord_file):\n",
    "                    writer.write(record.numpy())\n",
    "\n",
    "        print(f\"Concatenated TFRecord file saved to '{output_tfrecord_file}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = '../data/TFRecord_data'\n",
    "data = train_val_test_split_concatenate(root_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sarah_geexhp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
