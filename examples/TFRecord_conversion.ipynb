{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 09:50:37.216851: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736513437.235191 3396623 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736513437.240720 3396623 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-10 09:50:37.260205: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from geexhp.model import datasetup as dset\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to create tf.train.Features\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode()]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / list of floats.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _float_feature_list(value):\n",
    "    \"\"\"Returns a float_list from a float / list of floats.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to serialize a row into tf.train.Example\n",
    "def serialize_sample(row):\n",
    "    feature = {\n",
    "        'NOISY_ALBEDO_B-NIR' : _float_feature_list(row['NOISY_ALBEDO_B-NIR']),\n",
    "        'NOISY_ALBEDO_B-UV' : _float_feature_list(row['NOISY_ALBEDO_B-UV']),\n",
    "        'NOISY_ALBEDO_B-Vis' : _float_feature_list(row['NOISY_ALBEDO_B-Vis']),\n",
    "        'NOISY_ALBEDO_SS-NIR' : _float_feature_list(row['NOISY_ALBEDO_SS-NIR']),\n",
    "        'NOISY_ALBEDO_SS-UV' : _float_feature_list(row['NOISY_ALBEDO_SS-UV']),\n",
    "        'NOISY_ALBEDO_SS-Vis' : _float_feature_list(row['NOISY_ALBEDO_SS-Vis']),\n",
    "        'OBJECT-DIAMETER' : _float_feature(row['OBJECT-DIAMETER']),\n",
    "        'OBJECT-GRAVITY' : _float_feature(row['OBJECT-GRAVITY']),\n",
    "        'ATMOSPHERE-TEMPERATURE' : _float_feature(row['ATMOSPHERE-TEMPERATURE']),\n",
    "        'ATMOSPHERE-PRESSURE' : _float_feature(row['ATMOSPHERE-PRESSURE']),\n",
    "        'Earth_type' : _bytes_feature(row['Earth_type']),\n",
    "        'C2H6' : _float_feature(row['C2H6']),\n",
    "        'CH4' : _float_feature(row['CH4']),\n",
    "        'CO' : _float_feature(row['CO']),\n",
    "        'CO2' : _float_feature(row['CO2']),\n",
    "        'H2O' : _float_feature(row['H2O']),\n",
    "        'N2' : _float_feature(row['N2']),\n",
    "        'N2O' : _float_feature(row['N2O']),\n",
    "        'O2' : _float_feature(row['O2']),\n",
    "        'O3' : _float_feature(row['O3'])\n",
    "    }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = [\n",
    "    'NOISY_ALBEDO_B-NIR',\n",
    "    'NOISY_ALBEDO_B-UV',\n",
    "    'NOISY_ALBEDO_B-Vis',\n",
    "    'NOISY_ALBEDO_SS-NIR',\n",
    "    'NOISY_ALBEDO_SS-UV',\n",
    "    'NOISY_ALBEDO_SS-Vis',\n",
    "    'OBJECT-DIAMETER',\n",
    "    'OBJECT-GRAVITY',\n",
    "    'ATMOSPHERE-TEMPERATURE',\n",
    "    'ATMOSPHERE-PRESSURE',\n",
    "    'Earth_type'\n",
    "]\n",
    "\n",
    "molecules = [\n",
    "    'C2H6',\n",
    "    'CH4',\n",
    "    'CO',\n",
    "    'CO2',\n",
    "    'H2O',\n",
    "    'N2',\n",
    "    'N2O',\n",
    "    'O2',\n",
    "    'O3'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = '../parallel'\n",
    "\n",
    "folders = os.listdir(root_folder)\n",
    "\n",
    "# Count the total number of '.parquet' files\n",
    "file_count = sum(\n",
    "    len([file for file in files if file.endswith('.parquet')])\n",
    "    for _, _, files in os.walk(root_folder)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🌍 Progress: |\u001b[36m                              \u001b[0m|   0% (2/972 files) ⏳ [00:02 elapsed]"
     ]
    }
   ],
   "source": [
    "with tqdm(\n",
    "    total=file_count,\n",
    "    desc=\"🌍 Progress\",\n",
    "    dynamic_ncols=True,\n",
    "    colour='cyan',\n",
    "    bar_format=\"{desc}: |{bar:30}| {percentage:3.0f}% ({n_fmt}/{total_fmt} files) ⏳ [{elapsed} elapsed]\"\n",
    ") as pbar:\n",
    "    \n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join(root_folder, folder)\n",
    "\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue  # Skip stuff that is not a folder\n",
    "\n",
    "        files = os.listdir(folder_path)\n",
    "\n",
    "        for file in files:\n",
    "            # Some code\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "\n",
    "            if not file.endswith(\".parquet\"):\n",
    "                continue  # Skip non-parquet files\n",
    "\n",
    "            earth_type = file.split(\"_\")[0]\n",
    "            \n",
    "            df = pd.read_parquet(file_path)\n",
    "            df[\"Earth_type\"] = earth_type\n",
    "\n",
    "            noise_columns = [col for col in df.columns if \"NOISE_\" in col]\n",
    "            mask = ~df[noise_columns].map(lambda x: any(value > 10 for value in x)).any(axis=1)\n",
    "            df = df[mask]\n",
    "\n",
    "            df = dset.extract_abundances(df)\n",
    "\n",
    "            filtered_df = df.copy()\n",
    "            filtered_df = filtered_df[columns_of_interest]\n",
    "\n",
    "            # Get all the molecules abundances.\n",
    "            for molecule in molecules:\n",
    "                if molecule in df.columns:\n",
    "                    filtered_df[molecule] = df[molecule]\n",
    "                else:\n",
    "                    # Fill with zeros those who are not present.\n",
    "                    filtered_df[molecule] = 0\n",
    "            \n",
    "            record_dict = filtered_df.to_dict(orient=\"records\")\n",
    "\n",
    "            # Writing to TFRecord file\n",
    "            #   The files follow the following name structure:\n",
    "            #   {earth_type}_{origin_folder}_{original_range_of_samples}_{number_of_actual_samples}\n",
    "            tfrecord_file = f'{earth_type}_{folder}_{file.split(\"_\")[1]}_{len(record_dict)}.tfrecord'\n",
    "            save_root = '../data/TFRecord_data'\n",
    "            if not os.path.exists(save_root):\n",
    "                os.makedirs(save_root)\n",
    "            save_path_file = os.path.join(save_root, tfrecord_file)\n",
    "\n",
    "            with tf.io.TFRecordWriter(save_path_file) as writer:\n",
    "                for sample in record_dict:\n",
    "                    serialized_sample = serialize_sample(sample)\n",
    "                    writer.write(serialized_sample)\n",
    "\n",
    "            pbar.update(1)  # Update the progress bar for each file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sarah_geexhp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
